{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8585fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts info:\n",
    "#Input: File level dataset. Files: \"Nova.csv\",\"Ironic.csv\", \"Base.csv\"\n",
    "#Output: File level result. File: \"csv_commented_fileLevel.csv\"\n",
    "#Description: This script is used to generate the result for predicting lines to be revised for RQ1.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "data_nova = pd.read_csv('./dataset/fileLevel/Nova.csv', dtype=None, sep=',').to_numpy()\n",
    "data_ironic = pd.read_csv('./dataset/fileLevel/Ironic.csv', dtype=None, sep=',').to_numpy()\n",
    "data_base = pd.read_csv('./dataset/fileLevel/Base.csv', dtype=None, sep=',').to_numpy()\n",
    "\n",
    "model_path = './dataset/ml-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37370f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training/test datset\n",
    "def getDatasetFromRawData(project_source, data, bias):\n",
    "    row_data = data[0:,3]\n",
    "    row_data_Y = data[0:,0]\n",
    "    if project_source == \"qt\":\n",
    "        row_data_deletions = data[0:,6]\n",
    "        row_data_additions = data[0:,7]\n",
    "        row_data_changedLine = data[0:,8]\n",
    "    else:\n",
    "        row_data_deletions = data[0:,7]\n",
    "        row_data_additions = data[0:,8]\n",
    "        row_data_changedLine = data[0:,9]\n",
    "    Y_train = []\n",
    "    is_comment = 0\n",
    "    not_comment = 0\n",
    "    for element in row_data_Y:\n",
    "        if(element == 0):\n",
    "            Y_train.append(False)\n",
    "            not_comment += 1\n",
    "        else:\n",
    "            Y_train.append(True)\n",
    "            is_comment += 1\n",
    "    Y_train = np.array(Y_train)\n",
    "    #finding a index that wouldn't separate file in same changeId into both training dataset and test dataset\n",
    "    first = int(len(data)*0.6)\n",
    "    divider = int(len(data)*0.2) + first + bias\n",
    "\n",
    "    data_count_vect = CountVectorizer(min_df=2, max_df=0.5)\n",
    "\n",
    "    train_row_data = row_data[:divider]\n",
    "    test_row_data = row_data[divider:]\n",
    "\n",
    "    train_row_data_deletions = row_data_deletions[:divider]\n",
    "    test_row_data_deletions = row_data_deletions[divider:]\n",
    "\n",
    "    train_row_data_additions = row_data_additions[:divider]\n",
    "    test_row_data_additions = row_data_additions[divider:]\n",
    "\n",
    "    train_row_data_changedLine = row_data_changedLine[:divider]\n",
    "    test_row_data_changedLine = row_data_changedLine[divider:]\n",
    "\n",
    "    data_train_counts = data_count_vect.fit_transform(train_row_data)\n",
    "    data_test_counts = data_count_vect.transform(test_row_data)\n",
    "    \n",
    "    #add another three features(number of added lines, number of deleted lines and number of changed_lines)\n",
    "    final_train_X = np.hstack((data_train_counts.toarray(),train_row_data_deletions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_additions[:,None]))\n",
    "    final_train_X = np.hstack((final_train_X,train_row_data_changedLine[:,None]))\n",
    "\n",
    "    final_test_X = np.hstack((data_test_counts.toarray(),test_row_data_deletions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_additions[:,None]))\n",
    "    final_test_X = np.hstack((final_test_X,test_row_data_changedLine[:,None]))\n",
    "    final_train_y = Y_train[:divider]\n",
    "    final_test_y = Y_train[divider:]\n",
    "\n",
    "    del data_train_counts,data_test_counts,train_row_data,test_row_data,data,row_data,row_data_Y\n",
    "    return final_train_X,final_train_y,final_test_X,final_test_y,divider,data_count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be021fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show file level prediction result\n",
    "def printResult(x, y, model):\n",
    "    print(\"AUC:\",roc_auc_score(y, model.predict_proba(x)[:,1]))\n",
    "    print(\"Precision:\",precision_score(y, model.predict(x)))\n",
    "    print(\"Recall:\",recall_score(y, model.predict(x)))\n",
    "    print(\"F1:\",f1_score(y, model.predict(x)))\n",
    "    print(\"MCC:\",matthews_corrcoef(y, model.predict(x)))\n",
    "    print(\"Confusion matrix: \\n\",confusion_matrix(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e0c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random forest model\n",
    "def trainRFmodel(project,rf_train_X,rf_train_y,rf_test_X,rf_test_y,seed, bias):\n",
    "    train_rf_model_path = model_path+'/smote_abstr_number_df_2_rf_'+project+'-'+str(seed)+str(bias)+'.pkl'\n",
    "    if not os.path.exists(train_rf_model_path):\n",
    "        rf = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=seed)\n",
    "        rf_X, rf_y = SMOTE(k_neighbors=10, random_state=seed).fit_resample(rf_train_X, rf_train_y)\n",
    "        rf.fit(rf_X,rf_y)\n",
    "        rf_ouput = open(train_rf_model_path, 'wb')\n",
    "        pickle.dump(rf,rf_ouput)\n",
    "        print(\"finish to creat a new rf model\")\n",
    "    else:\n",
    "        with open(train_rf_model_path,'rb') as f:\n",
    "            rf = pickle.load(f)\n",
    "    printResult(rf_test_X,rf_test_y,rf)\n",
    "    return rf\n",
    "\n",
    "# TN FP\n",
    "# FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3be71cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression model\n",
    "def trainLGmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    train_lg_model_path = model_path+'/smote_abstr_number_df_2_lg_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_lg_model_path):\n",
    "        lg = linear_model.LogisticRegression(penalty='l2', C=1, solver = 'newton-cg', random_state=seed)\n",
    "        lg.fit(train_X,train_y)\n",
    "        lg_ouput = open(train_lg_model_path, 'wb')\n",
    "        pickle.dump(lg,lg_ouput)\n",
    "        print(\"finish to creat a new lg model\")\n",
    "    else:\n",
    "        with open(train_lg_model_path,'rb') as f:\n",
    "            lg = pickle.load(f)\n",
    "    printResult(test_X,test_y,lg)\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3d774cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree model\n",
    "def trainDTmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"DT seed:\" + str(seed))\n",
    "    train_dt_model_path = model_path+'/smote_abstr_number_df_2_dt_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dt_model_path):\n",
    "        dt = DecisionTreeClassifier(random_state=seed)\n",
    "        dt.fit(train_X,train_y)\n",
    "        dt_ouput = open(train_dt_model_path, 'wb')\n",
    "        pickle.dump(dt,dt_ouput)\n",
    "        print(\"finish to creat a new dt model\")\n",
    "    else:\n",
    "        with open(train_dt_model_path,'rb') as f:\n",
    "            dt = pickle.load(f)\n",
    "    printResult(test_X,test_y,dt)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08870498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB\n",
    "def trainDMmodel(project,train_X,train_y,test_X,test_y,seed):\n",
    "    print(\"dummy seed:\" + str(seed))\n",
    "    train_dm_model_path = model_path+'/smote_abstr_number_df_2_dm_'+project+'-'+str(seed)+'.pkl'\n",
    "    if not os.path.exists(train_dm_model_path):\n",
    "        dm = DummyClassifier(strategy='stratified',random_state=seed)\n",
    "        dm.fit(train_X, train_y)\n",
    "        dm_ouput = open(train_dm_model_path, 'wb')\n",
    "        pickle.dump(dm,dm_ouput)\n",
    "        print(\"finish to creat a new dm model\")\n",
    "    else:\n",
    "        with open(train_dm_model_path,'rb') as f:\n",
    "            dm = pickle.load(f)\n",
    "    printResult(test_X,test_y,dm)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cf6a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataStatastic(train_X, train_y, test_X, test_y,data_count_vect):\n",
    "    train_true_label = 0\n",
    "    test_true_label = 0\n",
    "    for label in train_y:\n",
    "        if label == 1:\n",
    "            train_true_label += 1\n",
    "    for label in test_y:\n",
    "        if label == 1:\n",
    "            test_true_label += 1\n",
    "    print(\"training dataset size:\", len(train_X))\n",
    "    print(\"training dataset positive label size:\", train_true_label, train_true_label/len(train_y))\n",
    "    print(\"test dataset size:\", len(test_X))\n",
    "    print(\"test dataset positive label size:\", test_true_label, test_true_label/len(test_X))\n",
    "    print(\"feature_size:\", len(data_count_vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97c6c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(project_source,seed,projectName,data,bias):\n",
    "    projectName = projectName\n",
    "    #RF\n",
    "    train_X, train_y, test_X, test_y,divider,data_count_vect = getDatasetFromRawData(project_source,data, bias)\n",
    "    rf = trainRFmodel(projectName,train_X, train_y, test_X, test_y,seed, bias)\n",
    "    lg = trainLGmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dt = trainDTmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    dm = trainDMmodel(projectName,train_X, train_y, test_X, test_y,seed)\n",
    "    return rf,lg,dt,dm, test_X, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b93b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputCsv():\n",
    "    csv_path = './dataset/csv/csv_RQ1_fileLevel.csv'\n",
    "    csv_file = open(csv_path,\"w\")\n",
    "    fieldnames = ['Technique','Datasets','Measure','Value']\n",
    "    csv_writer = csv.DictWriter(csv_file,quoting=csv.QUOTE_NONE,escapechar='', fieldnames= fieldnames) \n",
    "    rf_nova,lg_nova,dt_nova,dm_nova,test_X_nova, test_y_nova = getResult(\"openstack\",2,\"nova\",data_nova,5)\n",
    "    rf_ironic,lg_ironic,dt_ironic,dm_ironic,test_X_ironic, test_y_ironic = getResult(\"openstack\",2,\"ironic\",data_ironic,-4)\n",
    "    rf_base,lg_base,dt_base,dm_base,test_X_base, test_y_base = getResult(\"qt\",2,\"base\",data_base,6)\n",
    "    result = []\n",
    "    result = generateResult(result,\"nova\",rf_nova,lg_nova,dt_nova,dm_nova,test_X_nova, test_y_nova)\n",
    "    result = generateResult(result,\"ironic\",rf_ironic,lg_ironic,dt_ironic,dm_ironic,test_X_ironic, test_y_ironic)\n",
    "    result = generateResult(result,\"base\",rf_base,lg_base,dt_base,dm_base,test_X_base, test_y_base)\n",
    "    csv_writer.writeheader()\n",
    "    for row in result:\n",
    "        csv_writer.writerow(row)\n",
    "    return result\n",
    "\n",
    "def generateResult(result, project,rf,lg,dt,dm,x,y):\n",
    "    result = generateResultList(result, project,\"RF\",rf,x, y)\n",
    "    result = generateResultList(result, project,\"LG\",lg,x, y)\n",
    "    result = generateResultList(result, project,\"DT\",dt,x, y)\n",
    "    result = generateResultList(result, project,\"Random Guessing\",dm,x, y)\n",
    "    return result\n",
    "\n",
    "def generateResultList(result,project,name,model ,x, y):\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'AUC','Value':roc_auc_score(y, model.predict_proba(x)[:,1])})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Precision','Value':precision_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'Recall','Value':recall_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'F1 measure','Value':f1_score(y, model.predict(x))})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'MCC','Value':matthews_corrcoef(y, model.predict(x))})\n",
    "    tn, fp, fn, tp = confusion_matrix(y, model.predict(x)).ravel()\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true negative','Value':tn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false positive','Value':fp})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'false negative','Value':fn})\n",
    "    result.append({'Technique':name,'Datasets':project,'Measure':'true positive','Value':tp})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e37306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish to creat a new rf model\n",
      "AUC: 0.7809996495300066\n",
      "Precision: 0.5938864628820961\n",
      "Recall: 0.1878453038674033\n",
      "F1: 0.2854144805876181\n",
      "MCC: 0.20644728147802732\n",
      "Confusion matrix: \n",
      " [[1578   93]\n",
      " [ 588  136]]\n",
      "finish to creat a new lg model\n",
      "AUC: 0.6131104707870035\n",
      "Precision: 0.42996742671009774\n",
      "Recall: 0.18232044198895028\n",
      "F1: 0.2560620756547042\n",
      "MCC: 0.10659679028294676\n",
      "Confusion matrix: \n",
      " [[1496  175]\n",
      " [ 592  132]]\n",
      "DT seed:2\n",
      "finish to creat a new dt model\n",
      "AUC: 0.6682772581343754\n",
      "Precision: 0.3771712158808933\n",
      "Recall: 0.20994475138121546\n",
      "F1: 0.26974267968056787\n",
      "MCC: 0.07333162986785781\n",
      "Confusion matrix: \n",
      " [[1420  251]\n",
      " [ 572  152]]\n",
      "dummy seed:2\n",
      "finish to creat a new dm model\n",
      "AUC: 0.4895660784722153\n",
      "Precision: 0.2842465753424658\n",
      "Recall: 0.2292817679558011\n",
      "F1: 0.25382262996941896\n",
      "MCC: -0.022318727058299664\n",
      "Confusion matrix: \n",
      " [[1253  418]\n",
      " [ 558  166]]\n",
      "finish to creat a new rf model\n",
      "AUC: 0.7819424006726928\n",
      "Precision: 0.43089430894308944\n",
      "Recall: 0.39552238805970147\n",
      "F1: 0.4124513618677043\n",
      "MCC: 0.30755067924969126\n",
      "Confusion matrix: \n",
      " [[640  70]\n",
      " [ 81  53]]\n",
      "finish to creat a new lg model\n",
      "AUC: 0.5755413075467732\n",
      "Precision: 0.28187919463087246\n",
      "Recall: 0.31343283582089554\n",
      "F1: 0.29681978798586567\n",
      "MCC: 0.15597678093297995\n",
      "Confusion matrix: \n",
      " [[603 107]\n",
      " [ 92  42]]\n",
      "DT seed:2\n",
      "finish to creat a new dt model\n",
      "AUC: 0.6172482657136852\n",
      "Precision: 0.30337078651685395\n",
      "Recall: 0.40298507462686567\n",
      "F1: 0.3461538461538462\n",
      "MCC: 0.20455547349415093\n",
      "Confusion matrix: \n",
      " [[586 124]\n",
      " [ 80  54]]\n",
      "dummy seed:2\n",
      "finish to creat a new dm model\n",
      "AUC: 0.5018078620979609\n",
      "Precision: 0.16176470588235295\n",
      "Recall: 0.16417910447761194\n",
      "F1: 0.16296296296296298\n",
      "MCC: 0.0035941052097303184\n",
      "Confusion matrix: \n",
      " [[596 114]\n",
      " [112  22]]\n",
      "finish to creat a new rf model\n",
      "AUC: 0.7039880743849515\n",
      "Precision: 0.45614035087719296\n",
      "Recall: 0.12807881773399016\n",
      "F1: 0.2\n",
      "MCC: 0.17968026112940713\n",
      "Confusion matrix: \n",
      " [[3352   93]\n",
      " [ 531   78]]\n",
      "finish to creat a new lg model\n",
      "AUC: 0.5387897073648538\n",
      "Precision: 0.3140495867768595\n",
      "Recall: 0.18719211822660098\n",
      "F1: 0.23456790123456786\n",
      "MCC: 0.14379666076910633\n",
      "Confusion matrix: \n",
      " [[3196  249]\n",
      " [ 495  114]]\n",
      "DT seed:2\n",
      "finish to creat a new dt model\n",
      "AUC: 0.5555525368147359\n",
      "Precision: 0.3026315789473684\n",
      "Recall: 0.18883415435139572\n",
      "F1: 0.23255813953488372\n",
      "MCC: 0.13718763272586598\n",
      "Confusion matrix: \n",
      " [[3180  265]\n",
      " [ 494  115]]\n",
      "dummy seed:2\n",
      "finish to creat a new dm model\n",
      "AUC: 0.48613039530411034\n",
      "Precision: 0.12\n",
      "Recall: 0.09359605911330049\n",
      "F1: 0.1051660516605166\n",
      "MCC: -0.030815533029783803\n",
      "Confusion matrix: \n",
      " [[3027  418]\n",
      " [ 552   57]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.7809992362399198},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.5938864628820961},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.1878453038674033},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2854144805876181},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.20644728147802732},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1578},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 93},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 588},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 136},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6131104707870035},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.42996742671009774},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.18232044198895028},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2560620756547042},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.10659679028294676},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1496},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 175},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 592},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 132},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6682772581343754},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.3771712158808933},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.20994475138121546},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.26974267968056787},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.07333162986785781},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1420},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 251},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 572},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 152},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.4895660784722153},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.2842465753424658},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.2292817679558011},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.25382262996941896},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': -0.022318727058299664},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 1253},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 418},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 558},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'nova',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 166},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.7819424006726928},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.43089430894308944},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.39552238805970147},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.4124513618677043},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.30755067924969126},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 640},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 70},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 81},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 53},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5755413075467732},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.28187919463087246},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.31343283582089554},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.29681978798586567},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.15597678093297995},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 603},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 107},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 92},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 42},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.6172482657136852},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.30337078651685395},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.40298507462686567},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.3461538461538462},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.20455547349415093},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 586},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 124},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 80},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 54},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5018078620979609},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.16176470588235295},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.16417910447761194},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.16296296296296298},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.0035941052097303184},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 596},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 114},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 112},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'ironic',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 22},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.703988312706595},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.45614035087719296},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.12807881773399016},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.2},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.17968026112940713},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3352},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 93},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 531},\n",
       " {'Technique': 'RF',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 78},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5387897073648538},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.3140495867768595},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.18719211822660098},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.23456790123456786},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.14379666076910633},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3196},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 249},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 495},\n",
       " {'Technique': 'LG',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 114},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.5555525368147359},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.3026315789473684},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.18883415435139572},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.23255813953488372},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': 0.13718763272586598},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3180},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 265},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 494},\n",
       " {'Technique': 'DT',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 115},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'AUC',\n",
       "  'Value': 0.48613039530411034},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Precision',\n",
       "  'Value': 0.12},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'Recall',\n",
       "  'Value': 0.09359605911330049},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'F1 measure',\n",
       "  'Value': 0.1051660516605166},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'MCC',\n",
       "  'Value': -0.030815533029783803},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true negative',\n",
       "  'Value': 3027},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false positive',\n",
       "  'Value': 418},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'false negative',\n",
       "  'Value': 552},\n",
       " {'Technique': 'Random Guessing',\n",
       "  'Datasets': 'base',\n",
       "  'Measure': 'true positive',\n",
       "  'Value': 57}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 -4 6\n",
    "outputCsv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo_env",
   "language": "python",
   "name": "neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
